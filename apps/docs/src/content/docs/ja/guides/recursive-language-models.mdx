---
title: 深い再帰型言語モデルを構築する
description: 各エージェントがそれぞれ独立した Daytona サンドボックス内で動作する、再帰型言語モデルエージェントを実装します。
---

import { TabItem, Tabs } from '@astrojs/starlight/components'

このガイドでは、[Recursive Language Models](https://arxiv.org/abs/2512.24601)（Zhang, Kraska, Khattab）で提唱され、さらに [Prime Intellect](https://www.primeintellect.ai/blog/rlm) によって発展させられたアプローチに基づき、Daytona のサンドボックスを利用する再帰的言語モデル（RLM）エージェントシステムの構築方法を説明します。

元論文と Prime Intellect の実装は単一レベルの再帰（depth=1）に焦点を当てていますが、本ガイドではこの概念を **無制限の再帰深度** へと拡張します。エージェントはサブエージェントを生成でき、サブエージェントはさらにそのサブエージェントを生成できる、といった形で、階層的に再帰が続きます。各エージェントは、対象リポジトリを新たにクローンした独立した Daytona サンドボックス内で実行されます。

***

### 1. ワークフロー概要 \{#1-workflow-overview\}

このシステムは、エージェントがサブタスクを子エージェントに委譲できる再帰的なエージェントアーキテクチャを実装しています。

1. **初期化**: ルートエージェントがタスクを受け取り、リポジトリの最新のクローンが用意された Daytona サンドボックスを取得する
2. **反復**: エージェントがループを実行する: LLM 呼び出し → Python コードの抽出 → REPL での実行
3. **委譲**: コードは `rlm_query()` を呼び出してサブエージェントを生成でき、それぞれが独自のサンドボックスを持つ
4. **集約**: サブエージェントが結果を返し、親エージェントがそれらを統合し、必要に応じてさらにコードを実行する
5. **完了**: ルートエージェントがすべてのサブエージェントの結果を受け取り、Git パッチを生成する。すべてのサンドボックスはクリーンアップされる

```
Root Agent (depth=0)
├── Sub-Agent A (depth=1)
│   ├── Sub-Agent A1 (depth=2)
│   └── Sub-Agent A2 (depth=2)
└── Sub-Agent B (depth=1)
    ├── Sub-Agent B1 (depth=2)
    └── Sub-Agent B2 (depth=2)
```

各エージェントは、それぞれ専用の Daytona サンドボックス内でリポジトリを新たにクローンした環境として実行され、並列に探索を行えるようになります。

### 2. セットアップ \{#2-setup\}

#### リポジトリをクローンする \{#clone-the-repository\}

[Daytona リポジトリ](https://github.com/daytonaio/daytona.git)をクローンし、example ディレクトリに移動します。

```bash
git clone https://github.com/daytonaio/daytona.git
cd daytona/guides/python/recursive-language-models
```

#### 仮想環境を作成する \{#create-virtual-environment\}

```bash
python3.10 -m venv venv
source venv/bin/activate  # Windows の場合: venv\Scripts\activate
```

#### 依存関係をインストール \{#install-dependencies\}

```bash
pip install -e .
```

これにより、以下がインストールされます：

* `daytona` - サンドボックス管理用の Daytona SDK
* `litellm` - 任意のプロバイダー向けの統一 LLM インターフェース
* `typer` - CLI フレームワーク
* `pyyaml` - 設定ファイルの解析用ライブラリ

#### 環境を設定する \{#configure-environment\}

[Daytona Dashboard](https://app.daytona.io/dashboard/keys) から Daytona API キーを取得し、`.env` ファイルを作成します：

```bash
DAYTONA_API_KEY=your_daytona_api_key
LLM_API_KEY=your_llm_api_key
```

`LLM_API_KEY` は [LiteLLM](https://docs.litellm.ai/) 経由で使用され、OpenRouter、OpenAI、Anthropic などのプロバイダーをサポートします。

### 3. エージェントの実行 \{#3-running-an-agent\}

セットアップが完了したら、エージェントを実行してみましょう。以下は、scikit-learn 内の TODO コメントを調査する例です。

```bash
python run.py https://github.com/scikit-learn/scikit-learn \
  -p "このリポジトリ全体のTODOコメントを調査する。サブエージェントを生成して異なるモジュールを探索する。最も簡単なTODOを見つけて修正する。"
```

これはコードベースを探索するルートエージェントを起動し、並列調査のためにサブエージェントへ処理を委譲し、見つけた TODO のうち最も簡単なものを修正する git パッチを生成します。結果を確認し、後で実行を詳細にトレースしていきますが、その前にコードがどのように動作するのかを見てみましょう。

#### CLI オプション \{#cli-options\}

| オプション | 説明 |
|--------|-------------|
| `repo` | GitHub リポジトリ URL（必須） |
| `-p, --prompt` | エージェントに与えるタスク用プロンプト（必須） |
| `-b, --branch` | ブランチ名（任意） |
| `--commit` | 対象とするコミット SHA（任意） |
| `-c, --config` | 設定ファイルへのパス（デフォルト: `config.yaml`） |
| `-o, --output` | パッチの出力先ファイル（デフォルト: 標準出力） |

### 4. コードの理解 \{#4-understanding-the-code\}

エージェントシステムを構成する主要なコンポーネントを見ていきましょう。

#### エージェントの実行ループ \{#agent-execution-loop\}

各エージェントは、LLM を呼び出し、コードブロックを抽出して実行する反復ループを持ちます。`agent.py` における中核となるループは次のとおりです:

<Tabs>
  <TabItem label="Python" icon="seti:python">
    ```python
    def _run_loop(self) -> None:
        """Run the main iteration loop."""
        system_prompt = build_system_prompt(depth=self.depth)
        messages = [{"role": "system", "content": system_prompt}]
        execution_result = None

        for iteration in range(self.config.rlm.max_iterations):
            # Check global timeout
            if self._is_timeout():
                break

            # Build user prompt with previous execution result
            user_prompt = build_user_prompt(iteration, execution_result)
            messages.append({"role": "user", "content": user_prompt})

            # Get model completion
            response = self.client.completion(messages)
            messages.append({"role": "assistant", "content": response})

            # Execute code blocks in REPL
            repl_result = self.repl.execute_response(response)

            # Check for final answer
            if repl_result.final_answer is not None:
                self._result = repl_result.final_answer
                break

            # Format result for next iteration
            execution_result = format_execution_result(...)
    ```
  </TabItem>
</Tabs>

各イテレーションでは次の処理を行います:

1. 前回の実行結果をコンテキストとして含むプロンプトを構築する
2. LLM からの応答を取得する
3. Python のコードブロックを抽出して実行する
4. エージェントが結果を提出するために `FINAL()` を呼び出したかどうか確認する
5. 次のイテレーション用に出力を整形する

#### サブエージェントの生成 \{#sub-agent-spawning\}

エージェントコードが `rlm_query()` を呼び出すと、そのエージェント専用のサンドボックスを持つ新しいサブエージェントが作成されます:

<Tabs>
  <TabItem label="Python" icon="seti:python">
    ```python
    def _handle_rlm_query(self, task: str) -> str:
        """特定のタスク用のサブエージェントを生成する。"""
        # サンドボックス予算を確認
        if not self.sandbox_manager.budget.can_acquire():
            return "Error: sandbox budget exhausted"

        # 深さ + 1 のサブエージェントを作成
        sub_agent = RLMAgent(
            client=self.client,
            sandbox_manager=self.sandbox_manager,
            config=self.config,
            depth=self.depth + 1,
            task=task,
            # ... その他のパラメータ
        )

        # サブエージェントを実行（ブロッキング）
        result = sub_agent.run()

        # 必要に応じて省略して結果を返す
        return result.result or "No result"
    ```
  </TabItem>
</Tabs>

並列生成の場合は、`rlm_query_batched()` がスレッドプールを使用します:

<Tabs>
  <TabItem label="Python" icon="seti:python">
    ```python
    def _handle_rlm_query_batched(self, tasks: list[str]) -> list[str]:
        """複数のサブエージェントを並列に生成する。"""
        results = [""] * len(tasks)

        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_idx = {
                executor.submit(self._handle_rlm_query, task): i
                for i, task in enumerate(tasks)
            }
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                results[idx] = future.result()

        return results
    ```
  </TabItem>
</Tabs>

#### エージェントコードインターフェース \{#agent-code-interface\}

REPL 内では、エージェントは次の関数を利用できます:

| 関数 | 説明 |
|----------|-------------|
| `rlm_query(task)` | 単一のサブエージェントを生成し、結果文字列を返す |
| `rlm_query_batched(tasks)` | 複数のサブエージェントを並列に生成する |
| `FINAL(answer)` | 最終結果を送信する（root: パッチ抽出をトリガー） |
| `FINAL_VAR(var_name)` | 変数の値を結果として送信する |
| `edit_file(path, old, new)` | 構文検証付きでファイルを編集する |

エージェントが用いるサブエージェント生成パターンの例:

<Tabs>
  <TabItem label="Python" icon="seti:python">
    ```python
    # 複数のサブエージェントを生成して異なるモジュールを探索する
    results = rlm_query_batched([
        "Search for TODO comments in sklearn/linear_model/ and assess difficulty",
        "Search for TODO comments in sklearn/ensemble/ and assess difficulty",
        "Search for TODO comments in sklearn/tree/ and assess difficulty",
    ])

    for i, result in enumerate(results):
        print(f"=== Sub-agent {i+1} findings ===")
        print(result)
    ```
  </TabItem>
</Tabs>

### 5. 例を用いたウォークスルー \{#5-example-walkthrough\}

一般的な機械学習ライブラリである scikit-learn を対象にエージェントを実行した際に、どのような処理が行われるかを追ってみましょう。

```bash
python run.py https://github.com/scikit-learn/scikit-learn \
  -p "Investigate TODO comments across this repository. Spawn sub-agents to explore different modules under sklearn/ in parallel. For each TODO found, assess how difficult it would be to fix (easy/medium/hard). After gathering results, pick the easiest TODO and fix it."
```

scikit-learn には、部分文字列「# TODO」を含む行が約 400 行あることに注意してください。

**ステップ 1: ルートエージェントがリポジトリを探索し、深さ1のサブエージェントを生成する**

ルートエージェント（depth=0）はリポジトリ構造を調査し、すべての sklearn モジュールを特定し、並列に 25 個のサブエージェントを生成します:

<Tabs>
  <TabItem label="Python" icon="seti:python">
    ```python
    # 調査対象のサブディレクトリを定義
    subdirs = [
        "cluster", "compose", "covariance", "cross_decomposition", "datasets",
        "decomposition", "ensemble", "feature_extraction", "feature_selection",
        "gaussian_process", "impute", "inspection", "linear_model", "manifold",
        "metrics", "mixture", "model_selection", "neighbors", "neural_network",
        "preprocessing", "semi_supervised", "svm", "tree", "utils"
    ]

    # サブエージェント向けのクエリを作成
    queries = [
        f"Search for 'TODO' comments in 'sklearn/{subdir}/'. For each TODO found, provide: "
        f"1. The file path and line number. 2. The content of the TODO. 3. An assessment "
        f"of how difficult it would be to fix (easy/medium/hard) with a brief justification."
        for subdir in subdirs
    ]

    results = rlm_query_batched(queries)
    ```
  </TabItem>
</Tabs>

これら 25 個の各サブエージェントには、それぞれ専用の Daytona サンドボックスと、scikit-learn の新しいクローンが割り当てられます。

**ステップ 2: 深さ1エージェントが深さ2エージェントを生成する**

一部の深さ1エージェントは、自分の担当モジュールが大きすぎると判断し、さらにサブエージェントを生成します。たとえば、`sklearn/metrics/` エージェントは 3 つの深さ2エージェントを生成しました:

<Tabs>
  <TabItem label="Python" icon="seti:python">
    ```python
    # sklearn/metrics/ エージェント内部 (depth=1)
    # 多数の TODO を効率的に処理するため、サブディレクトリごとにサブエージェントを生成する

    tasks = [
        "Identify and assess TODOs in 'sklearn/metrics/cluster/'. Provide file, line, content, and difficulty.",
        "Identify and assess TODOs in 'sklearn/metrics/tests/'. Provide file, line, content, and difficulty.",
        "Identify and assess TODOs in 'sklearn/metrics/_plot/' and its 'tests' sub-directory."
    ]

    results = rlm_query_batched(tasks)
    ```
  </TabItem>
</Tabs>

**ステップ 3: 結果が上位に伝播する**

各サブエージェントは `FINAL()` を通じて検出結果を返します。結果は次のように上位へ流れます:

* 深さ2 → 深さ1: 特定のサブディレクトリに関する詳細な分析
* 深さ1 → ルート: 困難度評価付きのモジュールレベルのサマリー

**ステップ 4: ルートエージェントが統合して行動する**

ルートエージェントはすべての結果をレビューし、最も簡単に対応できる TODO を特定して修正を行います。

**ステップ 5: Git パッチを生成**

<Tabs>
  <TabItem label="Python" icon="seti:python">
    ```python
    import subprocess
    subprocess.run(['git', 'add', '-A'], cwd='/workspace')
    result = subprocess.run(['git', 'diff', '--cached', 'HEAD'],
                            capture_output=True, text=True, cwd='/workspace')
    FINAL(result.stdout)
    ```
  </TabItem>
</Tabs>

#### 結果 \{#results\}

* 実行時間: **316 秒**（約 5.3 分）
* 起動されたエージェント数: **40**（深さ 1 で 25、深さ 2 で 15）

**生成されたパッチ:**

```diff
diff --git a/sklearn/utils/_array_api.py b/sklearn/utils/_array_api.py
--- a/sklearn/utils/_array_api.py
+++ b/sklearn/utils/_array_api.py
@@ -19,8 +19,7 @@ from sklearn.externals.array_api_compat import numpy as np_compat
 from sklearn.utils._dataframe import is_df_or_series
 from sklearn.utils.fixes import parse_version

-# TODO: __all__を完成させる
-__all__ = ["xpx"]  # ruffを満足させるため、ここでxpxをインポートして再エクスポートする必要がある
+__all__ = ['device', 'get_namespace', 'get_namespace_and_device', 'indexing_dtype', 'move_to', 'size', 'supported_float_dtypes', 'xpx', 'yield_namespace_device_dtype_combinations', 'yield_namespaces']
```

エージェントは最も簡単な TODO（`sklearn/utils/_array_api.py` 内の `# TODO: complete __all__`）を見つけ、このモジュール内のすべての公開シンボルを `__all__` リストに追加して完成させました。

### 6. 設定 \{#6-configuration\}

`config.yaml` でエージェントを構成します:

<Tabs>
  <TabItem label="YAML" icon="seti:yaml">
    ```yaml
    # モデル設定 - LiteLLM 形式を使用
    model:
      name: "openrouter/google/gemini-3-flash-preview"

    # RLM 設定
    rlm:
      max_sandboxes: 50
      max_iterations: 50
      global_timeout: 3600
      result_truncation_limit: 10000
    ```
  </TabItem>
</Tabs>

| Parameter | Default | Description |
|-----------|---------|-------------|
| `model.name` | `openrouter/google/gemini-3-flash-preview` | LiteLLM 形式の LLM モデル |
| `rlm.max_sandboxes` | 50 | ロールアウト全体でのサンドボックスの最大合計数 |
| `rlm.max_iterations` | 50 | エージェントごとの最大反復回数 |
| `rlm.global_timeout` | 3600 | 合計タイムアウト（秒） |
| `rlm.result_truncation_limit` | 10000 | サブエージェントの結果の最大文字数 |

:::tip[スケーリングのヒント]

* より多くの並列探索を必要とするタスクでは `max_sandboxes` を増やしてください
* サンドボックスの予算は、ロールアウト期間全体を通じて作成されたサンドボックスの合計数を追跡します
* サブエージェントのサンドボックスは、処理完了後ただちに削除されます
  :::

### 7. 結果の確認 \{#7-viewing-results\}

結果は JSON ファイルとして `results/` ディレクトリに保存されます。内蔵ビューアを使用します：

```bash
python -m http.server 8000
# http://localhost:8000/viewer/ を開いてください
```

ビューアーでは次の機能を利用できます：

* エージェント階層のインタラクティブなツリー表示
* 各エージェントのコードと出力を含むイテレーションの詳細
* 統計情報：エージェント数、最大深度、総イテレーション数

### 8. 結論 \{#8-conclusion\}

現在の言語モデルは再帰的デリゲーションを活用するように特別に訓練されているわけではないため、RLM はまだベンチマーク上で単一エージェント手法を必ずしも上回っているわけではありません。しかし、このアーキテクチャは複雑なタスクに対して有望な特性を示しています。

scikit-learn の例では、エージェントツリー全体にわたって 40 個のエージェントが並列に動作し、それぞれが独自の隔離されたサンドボックス環境を持ちながら、全体の実行をわずか 5 分強で完了しました。このような並列性、すなわち各エージェントが他に影響を与えずに自由にファイルを変更し、テストを実行し、探索できるようにすることは、エージェントごとのサンドボックスがなければ実現が難しいでしょう。

**このアプローチの主な利点:**

* **再帰的分解**: 複雑なタスクは自然にサブタスクへと分解され、専門化されたエージェントによって処理される
* **分離された実行**: 各エージェントは新しいサンドボックスを割り当てられ、相互干渉を防ぐ
* **並列探索**: `rlm_query_batched()` により同時並行での探索が可能になる