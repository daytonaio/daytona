#!/usr/bin/env python3
"""
Script to convert async code to sync code using the unasync library.

This script transforms files from the _async folder to the _sync folder,
converting async/await patterns to synchronous equivalents, while:
  - preserving regions marked by # unasync: preserve start / # unasync: preserve end
  - dropping regions marked by # unasync: delete start / # unasync: delete end
  - stripping all Awaitable[...] and cleaning up Awaitable imports
  - replacing aiofiles.open calls with built-in open and removing aiofiles imports
"""

import logging
import re
import sys
import tempfile
from pathlib import Path

import unasync

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)

# Project paths
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

SOURCE_DIR = project_root / "src" / "daytona_sdk" / "_async"
TARGET_DIR = project_root / "src" / "daytona_sdk" / "_sync"

# Regex markers for blocks
MARKERS = {
    "preserve_start": re.compile(r"^\s*#\s*unasync:\s*preserve\s+start"),
    "preserve_end": re.compile(r"^\s*#\s*unasync:\s*preserve\s+end"),
    "delete_start": re.compile(r"^\s*#\s*unasync:\s*delete\s+start"),
    "delete_end": re.compile(r"^\s*#\s*unasync:\s*delete\s+end"),
}

# Simple token maps for unasync
ADDITIONAL_REPLACEMENTS = {
    # Async/await syntax
    "async def": "def",
    "async with": "with",
    "async for": "for",
    "await ": "",
    # Module & class renames
    "daytona_api_client_async": "daytona_api_client",
    "AsyncVolumeService": "VolumeService",
    "AsyncFileSystem": "FileSystem",
    "AsyncGit": "Git",
    "AsyncLspServer": "LspServer",
    "AsyncProcess": "Process",
    "AsyncDaytona": "Daytona",
    "AsyncSandbox": "Sandbox",
    # aiofiles replacement
    "aiofiles.open": "open",
}

# Complex regex-based tweaks
PRE_REPLACEMENTS = [
    (re.compile(r"\bAsync([A-Z]\w*)\b"), r"\1"),
]
POST_REPLACEMENTS = [
    # Remove any remaining 'await ' (including in docstrings)
    (re.compile(r"\bawait\s+"), ""),
    # Strip Sync prefix
    (re.compile(r"\bSync([A-Z]\w*)\b"), r"\1"),
    # httpx client fix
    (re.compile(r"httpx\.SyncClient\b"), "httpx.Client"),
    # Update module imports
    (re.compile(r"from daytona_sdk\._async"), "from daytona_sdk._sync"),
    # Documentation cleanup
    (re.compile(r"\basynchronous methods\b"), "methods"),
    (re.compile(r"\basynchronous\b"), "synchronous"),
    (re.compile(r"\basynchronously\b"), ""),
    # Replace aiofiles.open with built-in open
    (re.compile(r"\baiofiles\.open\b"), "open"),
    # Remove aiofiles imports
    (re.compile(r"^import aiofiles\s*$", flags=re.MULTILINE), ""),
    (re.compile(r"^from aiofiles(?:\.[\w_]+)? import .+$", flags=re.MULTILINE), ""),
]

# Auto-generation banner
AUTO_GEN_WARNING = (
    "# DO NOT EDIT THIS FILE MANUALLY.\n"
    "# This file is auto-generated by the unasync conversion script.\n"
    "# Edit the async source and re-run this script.\n\n"
)


def find_license_end(lines):
    """Locate end of license/header to inject banner."""
    license_end = 0
    for i, line in enumerate(lines):
        stripped = line.strip()
        if not stripped or stripped.startswith("#!") or stripped.startswith("#"):
            license_end = i + 1
        else:
            break
    return license_end


def pre_filter(src: Path, dst: Path) -> dict:
    """Copy src to dst, removing delete-blocks and preserving verbatim sections."""
    lines = src.read_text(encoding="utf-8").splitlines(keepends=True)
    out, block_map = [], {}
    buf, idx = [], 0
    in_preserve = in_delete = False

    for line in lines:
        if MARKERS["delete_start"].match(line):
            in_delete = True
            continue
        if MARKERS["delete_end"].match(line):
            in_delete = False
            continue
        if in_delete:
            continue
        if MARKERS["preserve_start"].match(line):
            in_preserve = True
            buf.clear()
            continue
        if MARKERS["preserve_end"].match(line):
            in_preserve = False
            placeholder = f"# UNASYNC_SKIP_BLOCK_{idx}\n"
            block_map[placeholder] = "".join(buf)
            out.append(placeholder)
            idx += 1
            continue
        if in_preserve:
            buf.append(line)
        else:
            out.append(line)

    dst.write_text("".join(out), encoding="utf-8")
    return block_map


def apply_replacements(text: str, replacements: list) -> str:
    for pattern, repl in replacements:
        text = pattern.sub(repl, text)
    return text


def restore_blocks(path: Path, block_map: dict):
    content = path.read_text(encoding="utf-8")
    for placeholder, block in block_map.items():
        content = content.replace(placeholder, block)
    path.write_text(content, encoding="utf-8")


def post_process(path: Path):
    text = path.read_text(encoding="utf-8")
    original = text
    text = apply_replacements(text, POST_REPLACEMENTS)
    # Strip type Awaitable[...] wrappers
    text = re.sub(r"Awaitable\[(.*?)\]", r"\1", text)

    # Clean up typing imports
    def clean_imports(m):
        imps = [i.strip() for i in m.group(1).split(",") if i.strip() != "Awaitable"]
        return f"from typing import {', '.join(imps)}" if imps else ""

    text = re.sub(r"^from typing import (.+)$", clean_imports, text, flags=re.MULTILINE)
    # Inject auto-gen banner if missing
    lines = text.splitlines(keepends=True)
    if not any("auto-generated by the unasync conversion script" in l for l in lines[:10]):
        idx = find_license_end(lines)
        lines.insert(idx, AUTO_GEN_WARNING)
        text = "".join(lines)
    if text != original:
        path.write_text(text, encoding="utf-8")
        logger.info(f"  Post-processed: {path.name}")


def main():
    TARGET_DIR.mkdir(parents=True, exist_ok=True)
    async_files = [f for f in SOURCE_DIR.glob("*.py") if not f.name.startswith("__")]

    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_dir = Path(tmpdir)
        sync_tmp = tmp_dir / "sync"
        sync_tmp.mkdir()

        placeholders = {}
        for src in async_files:
            tmp_file = tmp_dir / src.name
            placeholders[src.name] = pre_filter(src, tmp_file)
            # apply regex-based pre-replacements
            txt = tmp_file.read_text(encoding="utf-8")
            tmp_file.write_text(apply_replacements(txt, PRE_REPLACEMENTS), encoding="utf-8")

        rule = unasync.Rule(fromdir=str(tmp_dir), todir=str(sync_tmp), additional_replacements=ADDITIONAL_REPLACEMENTS)
        unasync.unasync_files([str(tmp_dir / f.name) for f in async_files], [rule])

        for gen in sync_tmp.glob("*.py"):
            dest = TARGET_DIR / gen.name
            dest.write_text(gen.read_text(encoding="utf-8"), encoding="utf-8")
            post_process(dest)
            restore_blocks(dest, placeholders[gen.name])

    logger.info("Unasync transformation completed successfully!")

    return 0


if __name__ == "__main__":
    sys.exit(main())
